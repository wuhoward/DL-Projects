{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "import scipy\n",
    "from scipy.io import loadmat\n",
    "import re\n",
    "\n",
    "import string\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "import random\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading skip thoughts vectors\n",
    "data_path = './dataset'\n",
    "df_train = pd.read_pickle(data_path + '/text2ImgData.pkl')\n",
    "\n",
    "#replace original captions with skip thoughts vectors\n",
    "filename = data_path + '/sample_caption_vectors.hdf5'\n",
    "f = h5py.File(filename, 'r')\n",
    "a_group_key = list(f.keys())[0]\n",
    "train_caption = np.array(f[a_group_key])\n",
    "\n",
    "filename = data_path + '/test_caption.hdf5'\n",
    "f = h5py.File(filename, 'r')\n",
    "a_group_key = list(f.keys())[0]\n",
    "test_caption = np.array(f[a_group_key])\n",
    "\n",
    "filename = data_path + '/sample_caption.hdf5'\n",
    "f = h5py.File(filename, 'r')\n",
    "a_group_key = list(f.keys())[0]\n",
    "sample_caption = list(f[a_group_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip thoughts index + RNN encoding\n",
    "df_train = pd.read_pickle(data_path + '/train_rnn.pkl')\n",
    "\n",
    "for i, captions in enumerate(df_train['Captions']):\n",
    "    caption_list = []\n",
    "    for j, c in enumerate(captions):\n",
    "        caption_list.append(np.hstack(([i*10+j], c)))\n",
    "    df_train.iloc[i, df_train.columns.get_loc('Captions')] = caption_list\n",
    "df_train.to_pickle('dataset/train_caption.pkl')\n",
    "\n",
    "df_test = pd.read_pickle(data_path + '/test_rnn.pkl')\n",
    "captions = []\n",
    "for i in range(len(df_test)):\n",
    "    captions.append(np.hstack(([i], df_test.iloc[i, df_test.columns.get_loc('Captions')])))\n",
    "\n",
    "d = {'Captions': captions, 'ID': df_test['ID'].values}\n",
    "df_test = pd.DataFrame(data=d)\n",
    "df_test.to_pickle('dataset/test_caption.pkl') \n",
    "\n",
    "sample_rnn = np.load('dataset/sample_rnn.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(input_image, shape):\n",
    "    float_img = tf.image.convert_image_dtype(input_image, tf.float32)\n",
    "    float_img.set_shape([None, None, 3])\n",
    "\n",
    "    short_side = tf.minimum(tf.shape(float_img)[0], tf.shape(float_img)[1])\n",
    "    float_img = tf.image.resize_image_with_crop_or_pad(float_img, short_side, short_side)\n",
    "    \n",
    "    image = tf.image.resize_images(float_img, size=[shape[0] * 76 // 64, shape[1] * 76 // 64])\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.random_crop(image, shape)\n",
    "    image = image * 2 - 1.\n",
    "    return image\n",
    "\n",
    "def training_data_generator(caption, image_path):\n",
    "    imagefile = tf.read_file(data_path + image_path)\n",
    "    image = tf.image.decode_image(imagefile, channels=3)\n",
    "    image = transform_image(image, [64, 64, 3])\n",
    "    return image, caption\n",
    "\n",
    "def training_data_generator_hr(caption, image_path):\n",
    "    imagefile = tf.read_file(data_path + image_path)\n",
    "    image = tf.image.decode_image(imagefile, channels=3)\n",
    "    image = transform_image(image, [256, 256, 3])\n",
    "    return image, caption\n",
    "\n",
    "def data_iterator(filenames, batch_size, data_generator):\n",
    "    # Load the training data into two NumPy arrays\n",
    "    df = pd.read_pickle(filenames)\n",
    "    captions = df['Captions'].values\n",
    "    image_path = df['ImagePath'].values\n",
    "\n",
    "    caption = []\n",
    "    paths = []\n",
    "\n",
    "    for i in range(len(captions)):\n",
    "        #caption.append(np.array(captions[i])[:, 1:])\n",
    "        caption.append(np.hstack((np.array(captions[i])[:, 1:], \n",
    "                                  train_caption[np.array(captions[i])[:, 0].astype(np.int32)][:, 2400:])))\n",
    "        paths.append(image_path[i])\n",
    "        \n",
    "    caption = np.array(caption)\n",
    "    paths = np.array(paths)\n",
    "    \n",
    "    # Assume that each row of `features` corresponds to the same row as `labels`.\n",
    "    assert caption.shape[0] == paths.shape[0]\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((caption, paths))\n",
    "    \n",
    "    dataset = dataset.map(data_generator, num_parallel_calls=4)\n",
    "    \n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(2 * batch_size)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    output_types = dataset.output_types\n",
    "    output_shapes = dataset.output_shapes\n",
    "\n",
    "    return iterator, output_types, output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator:\n",
    "\n",
    "    def __init__(self, noise_z, text, training_phase, hparas, reuse):\n",
    "        self.z = noise_z\n",
    "        self.text = text\n",
    "        self.batch_size = tf.shape(text)[0]\n",
    "        self.train = training_phase\n",
    "        self.hparas = hparas\n",
    "        self.gf_dim = 128\n",
    "        self.reuse = reuse\n",
    "        self.s = self.hparas['LR_SIZE']\n",
    "        self.s2, self.s4, self.s8, self.s16 = self.s // 2, self.s // 4, self.s // 8, self.s // 16\n",
    "        self.fc_initializer = tf.random_normal_initializer(0, 0.02)\n",
    "        self.deconv2d_initializer = tf.random_normal_initializer(0, 0.02)\n",
    "        self.gamma_initializer = tf.random_normal_initializer(1, 0.02)\n",
    "        self._build_model()\n",
    "\n",
    "    def _generate_condition(self, embed):\n",
    "        conditions = tf.layers.dense(embed, self.hparas['TEXT_DIM'] * 2, activation=tf.nn.leaky_relu,\n",
    "                                     kernel_initializer=self.fc_initializer)\n",
    "        mean = conditions[:, :self.hparas['TEXT_DIM']]\n",
    "        log_sigma = conditions[:, self.hparas['TEXT_DIM']:]\n",
    "        epsilon = tf.truncated_normal(tf.shape(mean))\n",
    "        stddev = tf.exp(log_sigma)\n",
    "        c = mean + stddev * epsilon\n",
    "        KLloss = -log_sigma + 0.5 * (-1 + tf.exp(2. * log_sigma) + tf.square(mean))\n",
    "        KLloss = tf.reduce_mean(KLloss)\n",
    "        return c, KLloss\n",
    "    \n",
    "    def _deconv_bn_relu(self, inputs, W, out_shape):\n",
    "        node = tf.nn.conv2d_transpose(inputs, W, output_shape=out_shape, strides=[1,2,2,1], padding='SAME')\n",
    "        node = tf.layers.batch_normalization(node, training=self.train, momentum=0.9, epsilon=1e-5, \n",
    "                                             gamma_initializer=self.gamma_initializer)\n",
    "        node = tf.nn.relu(node)\n",
    "        return node\n",
    "\n",
    "    def _build_model(self):\n",
    "        with tf.variable_scope('generator_1', reuse=self.reuse): \n",
    "            c, self.KLloss = self._generate_condition(self.text)\n",
    "            \n",
    "            z_text_concat = tf.concat([c, self.z], axis=1)\n",
    "            g_net = tf.layers.dense(z_text_concat, self.s16 * self.s16 * self.gf_dim * 8, \n",
    "                                    kernel_initializer=self.fc_initializer)\n",
    "            g_net = tf.reshape(g_net, [-1, self.s16, self.s16, self.gf_dim * 8])\n",
    "            g_net = tf.layers.batch_normalization(g_net, training=self.train, momentum=0.9, epsilon=1e-5, \n",
    "                                             gamma_initializer=self.gamma_initializer)\n",
    "            g_net = tf.nn.relu(g_net)\n",
    "            \n",
    "            W1 = tf.get_variable(\"weights1\", shape=[4, 4, self.gf_dim * 4, self.gf_dim * 8], initializer=self.deconv2d_initializer)\n",
    "            g_net = self._deconv_bn_relu(g_net, W1, [self.batch_size, self.s8, self.s8, self.gf_dim * 4])\n",
    "            \n",
    "            W2 = tf.get_variable(\"weights2\", shape=[4, 4, self.gf_dim * 2, self.gf_dim * 4], initializer=self.deconv2d_initializer)\n",
    "            g_net = self._deconv_bn_relu(g_net, W2, [self.batch_size, self.s4, self.s4, self.gf_dim * 2])\n",
    "            \n",
    "            W3 = tf.get_variable(\"weights3\", shape=[4, 4, self.gf_dim, self.gf_dim * 2], initializer=self.deconv2d_initializer)\n",
    "            g_net = self._deconv_bn_relu(g_net, W3, [self.batch_size, self.s2, self.s2, self.gf_dim])\n",
    "            \n",
    "            W4 = tf.get_variable(\"weights4\", shape=[4, 4, 3, self.gf_dim], initializer=self.deconv2d_initializer)\n",
    "            g_net = tf.nn.conv2d_transpose(g_net, W4, output_shape=[self.batch_size, self.s, self.s, 3], \n",
    "                                           strides=[1,2,2,1], padding='SAME')\n",
    "            g_net = tf.nn.tanh(g_net)\n",
    "\n",
    "            self.outputs = g_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator:\n",
    "\n",
    "    def __init__(self, image, text, training_phase, hparas, reuse):\n",
    "        self.image = image\n",
    "        self.text = text\n",
    "        self.train = training_phase\n",
    "        self.hparas = hparas\n",
    "        self.df_dim = 64\n",
    "        self.reuse = reuse\n",
    "        self.fc_initializer = tf.random_normal_initializer(0, 0.02)\n",
    "        self.conv2d_initializer = tf.truncated_normal_initializer(0, 0.02)\n",
    "        self.gamma_initializer = tf.random_normal_initializer(1, 0.02)\n",
    "        self.s = self.hparas['LR_SIZE']\n",
    "        self.s2, self.s4, self.s8, self.s16 = self.s // 2, self.s // 4, self.s // 8, self.s // 16\n",
    "        self._build_model()\n",
    "        \n",
    "    def _conv_bn_leaky(self, inputs, out_dim, ks, ss):\n",
    "        node = tf.layers.conv2d(inputs, out_dim, kernel_size=ks, strides=ss,\n",
    "                                padding='SAME', use_bias=False, kernel_initializer=self.conv2d_initializer)\n",
    "        node = tf.layers.batch_normalization(node, training=self.train, momentum=0.9, epsilon=1e-5, \n",
    "                                             gamma_initializer=self.gamma_initializer)\n",
    "        node = tf.nn.leaky_relu(node)\n",
    "        return node\n",
    "\n",
    "    def _build_model(self):\n",
    "        with tf.variable_scope('discriminator_1', reuse=self.reuse):\n",
    "            text_decode = tf.layers.dense(self.text, self.hparas['TEXT_DIM'], activation=tf.nn.leaky_relu,\n",
    "                                          kernel_initializer=self.fc_initializer)\n",
    "            text_decode = tf.expand_dims(tf.expand_dims(text_decode, 1), 1)\n",
    "            text_decode = tf.tile(text_decode, [1, self.s16, self.s16, 1])\n",
    "            \n",
    "            image_decode = tf.layers.conv2d(self.image, self.df_dim , kernel_size=[4, 4], strides=[2, 2],\n",
    "                                            padding='SAME', activation=tf.nn.leaky_relu, \n",
    "                                            use_bias=False, kernel_initializer=self.conv2d_initializer)\n",
    "            \n",
    "            image_decode = self._conv_bn_leaky(image_decode, self.df_dim * 2, [4, 4], [2, 2])\n",
    "            image_decode = self._conv_bn_leaky(image_decode, self.df_dim * 4, [4, 4], [2, 2])\n",
    "            image_decode = self._conv_bn_leaky(image_decode, self.df_dim * 8, [4, 4], [2, 2])\n",
    "            \n",
    "            concat_decode = tf.concat([image_decode, text_decode], axis=3)\n",
    "            concat_decode = self._conv_bn_leaky(concat_decode,  self.df_dim * 8, [1, 1], [1, 1])\n",
    "\n",
    "            concat_decode = tf.layers.conv2d(concat_decode, 1, kernel_size=[self.s16, self.s16], strides=[self.s16, self.s16],\n",
    "                                            padding='SAME', use_bias=False, kernel_initializer=self.conv2d_initializer)\n",
    "\n",
    "            self.logits = concat_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator_Complex:\n",
    "\n",
    "    def __init__(self, noise_z, text, training_phase, hparas, reuse):\n",
    "        self.z = noise_z\n",
    "        self.text = text\n",
    "        self.batch_size = tf.shape(text)[0]\n",
    "        self.train = training_phase\n",
    "        self.hparas = hparas\n",
    "        self.gf_dim = 128\n",
    "        self.reuse = reuse\n",
    "        self.s = self.hparas['LR_SIZE']\n",
    "        self.s2, self.s4, self.s8, self.s16 = self.s // 2, self.s // 4, self.s // 8, self.s // 16\n",
    "        self.fc_initializer = tf.random_normal_initializer(0, 0.02)\n",
    "        self.deconv2d_initializer = tf.random_normal_initializer(0, 0.02)\n",
    "        self.gamma_initializer = tf.random_normal_initializer(1, 0.02)\n",
    "        self._build_model()\n",
    "\n",
    "    def _generate_condition(self, embed):\n",
    "        conditions = tf.layers.dense(embed, self.hparas['TEXT_DIM'] * 2, activation=tf.nn.leaky_relu,\n",
    "                                     kernel_initializer=self.fc_initializer)\n",
    "        mean = conditions[:, :self.hparas['TEXT_DIM']]\n",
    "        log_sigma = conditions[:, self.hparas['TEXT_DIM']:]\n",
    "        epsilon = tf.truncated_normal(tf.shape(mean))\n",
    "        stddev = tf.exp(log_sigma)\n",
    "        c = mean + stddev * epsilon\n",
    "        KLloss = -log_sigma + 0.5 * (-1 + tf.exp(2. * log_sigma) + tf.square(mean))\n",
    "        KLloss = tf.reduce_mean(KLloss)\n",
    "        return c, KLloss\n",
    "    \n",
    "    def _conv_bn_relu(self, inputs, out_shape, ks, ss):\n",
    "        node = tf.layers.conv2d(inputs, filters=out_shape , kernel_size=ks, strides=ss, padding='SAME', use_bias=False)\n",
    "        node = tf.layers.batch_normalization(node, training=self.train, momentum=0.9, epsilon=1e-5, \n",
    "                                             gamma_initializer=self.gamma_initializer)\n",
    "        node = tf.nn.relu(node)\n",
    "        return node\n",
    "    \n",
    "    def _conv_bn(self, inputs, out_shape, ks, ss):\n",
    "        node = tf.layers.conv2d(inputs, filters = out_shape , kernel_size=ks, strides=ss, padding='SAME', use_bias=False)\n",
    "        node = tf.layers.batch_normalization(node, training=self.train, momentum=0.9, epsilon=1e-5, \n",
    "                                             gamma_initializer=self.gamma_initializer)\n",
    "        return node\n",
    "\n",
    "    def _build_model(self):\n",
    "        with tf.variable_scope('generator_1', reuse=self.reuse): \n",
    "            c, self.KLloss = self._generate_condition(self.text)\n",
    "            \n",
    "            z_text_concat = tf.concat([c, self.z], axis=1)\n",
    "            node1_0 = tf.layers.dense(z_text_concat, self.s16 * self.s16 * self.gf_dim * 8,\n",
    "                                      kernel_initializer=self.fc_initializer)\n",
    "            node1_0 = tf.layers.batch_normalization(node1_0, training=self.train, momentum=0.9, epsilon=1e-5, \n",
    "                                             gamma_initializer=self.gamma_initializer)\n",
    "            node1_0 = tf.reshape(node1_0, [-1, self.s16, self.s16, self.gf_dim * 8])\n",
    "            \n",
    "            node1_1 = self._conv_bn_relu(node1_0, self.gf_dim * 2, [1, 1], [1, 1])\n",
    "            node1_1 = self._conv_bn_relu(node1_1, self.gf_dim * 2, [3, 3], [1, 1])\n",
    "            node1_1 = self._conv_bn(node1_1, self.gf_dim * 8, [3, 3], [1, 1])            \n",
    "                        \n",
    "            node1 = tf.add(node1_0, node1_1)\n",
    "            node1 = tf.nn.relu(node1)\n",
    "            \n",
    "            node2_0 = tf.image.resize_nearest_neighbor(node1, size=[self.s8, self.s8])\n",
    "            node2_0 = self._conv_bn(node2_0, self.gf_dim * 4, [3, 3], [1, 1])  \n",
    "            node2_1 = self._conv_bn_relu(node2_0, self.gf_dim * 1, [1, 1], [1, 1])\n",
    "            node2_1 = self._conv_bn_relu(node2_1, self.gf_dim * 1, [3, 3], [1, 1])\n",
    "            node2_1 = self._conv_bn(node2_1, self.gf_dim * 4, [3, 3], [1, 1])  \n",
    "            node2 = tf.add(node2_0, node2_1)\n",
    "            node2 = tf.nn.relu(node2)\n",
    "            \n",
    "            output_tensor = tf.image.resize_nearest_neighbor(node2, size=[self.s4, self.s4])\n",
    "            output_tensor = self._conv_bn_relu(output_tensor, self.gf_dim * 2, [3, 3], [1, 1])\n",
    "            output_tensor = tf.image.resize_nearest_neighbor(output_tensor, size=[self.s2, self.s2])         \n",
    "            output_tensor = self._conv_bn_relu(output_tensor, self.gf_dim, [3, 3], [1, 1])\n",
    "   \n",
    "            output_tensor = tf.image.resize_nearest_neighbor(output_tensor, size=[self.s, self.s])\n",
    "            output_tensor = tf.layers.conv2d(output_tensor, 3, kernel_size=[3, 3], strides=[1, 1], \n",
    "                                             padding ='SAME', use_bias=False)\n",
    "            output_tensor = tf.nn.tanh(output_tensor)\n",
    "            \n",
    "            self.outputs = output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator_Complex:\n",
    "\n",
    "    def __init__(self, image, text, training_phase, hparas, reuse):\n",
    "        self.image = image\n",
    "        self.text = text\n",
    "        self.train = training_phase\n",
    "        self.hparas = hparas\n",
    "        self.df_dim = 64 \n",
    "        self.reuse = reuse\n",
    "        self.fc_initializer = tf.random_normal_initializer(0, 0.02)\n",
    "        self.conv2d_initializer = tf.truncated_normal_initializer(0, 0.02)\n",
    "        self.gamma_initializer = tf.random_normal_initializer(1, 0.02)\n",
    "        self.s = self.hparas['LR_SIZE']\n",
    "        self.s2, self.s4, self.s8, self.s16 = self.s // 2, self.s // 4, self.s // 8, self.s // 16\n",
    "        self._build_model()\n",
    "        \n",
    "    def _conv_bn_leaky(self, inputs, out_dim, ks, ss):\n",
    "        node = tf.layers.conv2d(inputs, out_dim, kernel_size=ks, strides=ss,\n",
    "                                padding='SAME', use_bias=False, kernel_initializer=self.conv2d_initializer)\n",
    "        node = tf.layers.batch_normalization(node, training=self.train, momentum=0.9, epsilon=1e-5, \n",
    "                                             gamma_initializer=self.gamma_initializer)\n",
    "        node = tf.nn.leaky_relu(node)\n",
    "        return node\n",
    "    \n",
    "    def _conv_bn(self, inputs, out_dim, ks, ss):\n",
    "        node = tf.layers.conv2d(inputs, out_dim, kernel_size=ks, strides=ss,\n",
    "                                padding='SAME', use_bias=False, kernel_initializer=self.conv2d_initializer)\n",
    "        node = tf.layers.batch_normalization(node, training=self.train, momentum=0.9, epsilon=1e-5, \n",
    "                                             gamma_initializer=self.gamma_initializer)\n",
    "        return node\n",
    "\n",
    "    def _build_model(self):\n",
    "        with tf.variable_scope('discriminator_1', reuse=self.reuse):\n",
    "            text_decode = tf.layers.dense(self.text, self.hparas['TEXT_DIM'], activation=tf.nn.leaky_relu,\n",
    "                                          kernel_initializer=self.fc_initializer)\n",
    "            text_decode = tf.expand_dims(tf.expand_dims(text_decode, 1), 1)\n",
    "            text_decode = tf.tile(text_decode, [1, self.s16, self.s16, 1]) \n",
    "            \n",
    "            node1_0 = tf.layers.conv2d(self.image, self.df_dim , kernel_size=[4, 4], strides=[2, 2],\n",
    "                                       padding='SAME', use_bias=False, kernel_initializer=self.conv2d_initializer)\n",
    "            node1_0 = tf.nn.leaky_relu(node1_0)\n",
    "            \n",
    "            node1_0 = self._conv_bn_leaky(node1_0, self.df_dim * 2, [4, 4], [2, 2])\n",
    "            node1_0 = self._conv_bn(node1_0, self.df_dim * 4, [4, 4], [2, 2])\n",
    "            node1_0 = self._conv_bn(node1_0, self.df_dim * 8, [4, 4], [2, 2])\n",
    "            \n",
    "            node1_1 = self._conv_bn_leaky(node1_0, self.df_dim * 2, [1, 1], [1, 1])\n",
    "            node1_1 = self._conv_bn_leaky(node1_1, self.df_dim * 2, [3, 3], [1, 1])\n",
    "            node1_1 = self._conv_bn(node1_1, self.df_dim * 8, [3, 3], [1, 1])\n",
    "                        \n",
    "            node1 = tf.add(node1_0, node1_1)\n",
    "            node1 = tf.nn.leaky_relu(node1)\n",
    "            \n",
    "            concat_decode = tf.concat([node1, text_decode], axis=3)\n",
    "            \n",
    "            concat_decode = self._conv_bn_leaky(concat_decode, self.df_dim * 8, [1, 1], [1, 1])\n",
    "            concat_decode = tf.layers.conv2d(concat_decode, 1, kernel_size=[self.s16, self.s16], strides=[self.s16, self.s16],\n",
    "                                            padding='SAME', use_bias=False, kernel_initializer=self.conv2d_initializer)\n",
    "\n",
    "            self.logits = concat_decode\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator_2:\n",
    "\n",
    "    def __init__(self, image, text, training_phase, hparas, reuse):\n",
    "        self.image = image\n",
    "        self.text = text\n",
    "        self.batch_size = tf.shape(text)[0]\n",
    "        self.train = training_phase\n",
    "        self.hparas = hparas\n",
    "        self.gf_dim = 128\n",
    "        self.reuse = reuse\n",
    "        self.s = self.hparas['LR_SIZE']\n",
    "        self.s2, self.s4, self.s8, self.s16 = self.s // 2, self.s // 4, self.s // 8, self.s // 16\n",
    "        self.fc_initializer = tf.random_normal_initializer(0, 0.02)\n",
    "        self.conv2d_initializer = tf.truncated_normal_initializer(0, 0.02)\n",
    "        self.gamma_initializer = tf.random_normal_initializer(1, 0.02)\n",
    "        self._build_model()\n",
    "\n",
    "    def _generate_condition(self, inputs):\n",
    "        conditions = tf.layers.dense(inputs, self.hparas['TEXT_DIM'] * 2, activation=tf.nn.leaky_relu,\n",
    "                                     kernel_initializer=self.fc_initializer)\n",
    "        mean = conditions[:, :self.hparas['TEXT_DIM']]\n",
    "        log_sigma = conditions[:, self.hparas['TEXT_DIM']:]\n",
    "        epsilon = tf.truncated_normal(tf.shape(mean))\n",
    "        stddev = tf.exp(log_sigma)\n",
    "        c = mean + stddev * epsilon\n",
    "        KLloss = -log_sigma + 0.5 * (-1 + tf.exp(2. * log_sigma) + tf.square(mean))\n",
    "        KLloss = tf.reduce_mean(KLloss)\n",
    "        return c, KLloss\n",
    "    \n",
    "    def _conv_bn_relu(self, inputs, out_dim, ks, ss):\n",
    "        node = tf.layers.conv2d(inputs, out_dim, kernel_size=ks, strides=ss,\n",
    "                                padding='SAME', use_bias=False, kernel_initializer=self.conv2d_initializer)\n",
    "        node = tf.layers.batch_normalization(node, training=self.train, momentum=0.9, epsilon=1e-5, \n",
    "                                             gamma_initializer=self.gamma_initializer)\n",
    "        node = tf.nn.leaky_relu(node)\n",
    "        return node\n",
    "    \n",
    "    def _residual_block(self, inputs):\n",
    "        node = self._conv_bn_relu(inputs, self.gf_dim * 4, [3, 3], [1, 1])\n",
    "        node = tf.layers.conv2d(node, self.gf_dim * 4, kernel_size=[3, 3], strides=[1, 1],\n",
    "                                padding='SAME', use_bias=False, kernel_initializer=self.conv2d_initializer)\n",
    "        node = tf.layers.batch_normalization(node, training=self.train, momentum=0.9, epsilon=1e-5, \n",
    "                                             gamma_initializer=self.gamma_initializer)\n",
    "        node = node + inputs\n",
    "        node = tf.nn.relu(node)\n",
    "        return node\n",
    "\n",
    "    def _build_model(self):\n",
    "        with tf.variable_scope('generator_2', reuse=self.reuse): \n",
    "\n",
    "            #ecnode image\n",
    "            image_encode = tf.layers.conv2d(self.image, self.gf_dim, kernel_size=[3, 3], strides=[1, 1],\n",
    "                                            padding='SAME', use_bias=False, kernel_initializer=self.conv2d_initializer)\n",
    "            image_encode = tf.nn.relu(image_encode)\n",
    "            image_encode = self._conv_bn_relu(image_encode, self.gf_dim * 2, [4, 4], [2, 2])\n",
    "            image_encode = self._conv_bn_relu(image_encode, self.gf_dim * 4, [4, 4], [2, 2])\n",
    "            \n",
    "            c, self.KLloss = self._generate_condition(self.text)\n",
    "            c = tf.expand_dims(tf.expand_dims(c, 1), 1)\n",
    "            c = tf.tile(c, [1, self.s4, self.s4, 1])\n",
    "            \n",
    "            g_net = tf.concat([image_encode, c], axis=3)\n",
    "            g_net = self._conv_bn_relu(g_net, self.gf_dim * 4, [3, 3], [1, 1])\n",
    "            \n",
    "            g_net = self._residual_block(g_net)\n",
    "            g_net = self._residual_block(g_net)\n",
    "            g_net = self._residual_block(g_net)\n",
    "            g_net = self._residual_block(g_net)\n",
    "            \n",
    "            g_net = tf.image.resize_nearest_neighbor(g_net, [self.s2, self.s2])\n",
    "            g_net = self._conv_bn_relu(g_net, self.gf_dim * 2, [3, 3], [1, 1])\n",
    "            g_net = tf.image.resize_nearest_neighbor(g_net, [self.s, self.s])\n",
    "            g_net = self._conv_bn_relu(g_net, self.gf_dim, [3, 3], [1, 1])\n",
    "            g_net = tf.image.resize_nearest_neighbor(g_net, [self.s * 2, self.s * 2])\n",
    "            g_net = self._conv_bn_relu(g_net, self.gf_dim // 2, [3, 3], [1, 1])\n",
    "            g_net = tf.image.resize_nearest_neighbor(g_net, [self.s * 4, self.s * 4])\n",
    "            g_net = self._conv_bn_relu(g_net, self.gf_dim // 4, [3, 3], [1, 1])\n",
    "            \n",
    "            g_net = tf.layers.conv2d(g_net, 3, kernel_size=[3, 3], strides=[1, 1],\n",
    "                                padding='SAME', use_bias=False, kernel_initializer=self.conv2d_initializer)\n",
    "            g_net = tf.nn.tanh(g_net)\n",
    "\n",
    "            self.outputs = g_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator_2:\n",
    "\n",
    "    def __init__(self, image, text, training_phase, hparas, reuse):\n",
    "        self.image = image\n",
    "        self.text = text\n",
    "        self.train = training_phase\n",
    "        self.hparas = hparas\n",
    "        self.df_dim = 64  \n",
    "        self.reuse = reuse\n",
    "        self.fc_initializer = tf.random_normal_initializer(0, 0.02)\n",
    "        self.conv2d_initializer = tf.truncated_normal_initializer(0, 0.02)\n",
    "        self.gamma_initializer = tf.random_normal_initializer(1, 0.02)\n",
    "        self.s = self.hparas['LR_SIZE']\n",
    "        self.s2, self.s4, self.s8, self.s16 = self.s // 2, self.s // 4, self.s // 8, self.s // 16\n",
    "        self._build_model()\n",
    "        \n",
    "    def _conv_bn_leaky(self, inputs, out_dim, ks, ss):\n",
    "        node = tf.layers.conv2d(inputs, out_dim, kernel_size=ks, strides=ss,\n",
    "                                padding='SAME', use_bias=False, kernel_initializer=self.conv2d_initializer)\n",
    "        node = tf.layers.batch_normalization(node, training=self.train, momentum=0.9, epsilon=1e-5, \n",
    "                                             gamma_initializer=self.gamma_initializer)\n",
    "        node = tf.nn.leaky_relu(node)\n",
    "        return node\n",
    "\n",
    "    def _build_model(self):\n",
    "        with tf.variable_scope('discriminator_2', reuse=self.reuse):\n",
    "            text_decode = tf.layers.dense(self.text, self.hparas['TEXT_DIM'], activation=tf.nn.leaky_relu,\n",
    "                                          kernel_initializer=self.fc_initializer)\n",
    "            text_decode = tf.expand_dims(tf.expand_dims(text_decode, 1), 1)\n",
    "            text_decode = tf.tile(text_decode, [1, self.s16, self.s16, 1])\n",
    "            \n",
    "            image_decode = tf.layers.conv2d(self.image, self.df_dim, kernel_size=[4, 4], strides=[2, 2],\n",
    "                                            padding='SAME', activation=tf.nn.leaky_relu, \n",
    "                                            use_bias=False, kernel_initializer=self.conv2d_initializer)\n",
    "            \n",
    "            image_decode = self._conv_bn_leaky(image_decode, self.df_dim * 2, [4, 4], [2, 2])\n",
    "            image_decode = self._conv_bn_leaky(image_decode, self.df_dim * 4, [4, 4], [2, 2])\n",
    "            image_decode = self._conv_bn_leaky(image_decode, self.df_dim * 8, [4, 4], [2, 2])\n",
    "            image_decode = self._conv_bn_leaky(image_decode, self.df_dim * 16, [4, 4], [2, 2])\n",
    "            image_decode = self._conv_bn_leaky(image_decode, self.df_dim * 32, [4, 4], [2, 2])\n",
    "            image_decode = self._conv_bn_leaky(image_decode, self.df_dim * 16, [1, 1], [1, 1])\n",
    "            image_decode = tf.layers.conv2d(image_decode, self.df_dim * 8, kernel_size=[1, 1], strides=[1, 1],\n",
    "                                            padding='SAME', use_bias=False, kernel_initializer=self.conv2d_initializer)\n",
    "            image_decode = tf.layers.batch_normalization(image_decode, training=self.train, momentum=0.9, epsilon=1e-5, \n",
    "                                             gamma_initializer=self.gamma_initializer)\n",
    "            \n",
    "            image_decode_2 = self._conv_bn_leaky(image_decode, self.df_dim * 2, [1, 1], [1, 1])\n",
    "            image_decode_2 = self._conv_bn_leaky(image_decode_2, self.df_dim * 2, [3, 3], [1, 1])\n",
    "            image_decode_2 = tf.layers.conv2d(image_decode_2, self.df_dim * 8, kernel_size=[3, 3], strides=[1, 1],\n",
    "                                            padding='SAME', use_bias=False, kernel_initializer=self.conv2d_initializer)\n",
    "            image_decode_2 = tf.layers.batch_normalization(image_decode_2, training=self.train, momentum=0.9, epsilon=1e-5, \n",
    "                                             gamma_initializer=self.gamma_initializer)\n",
    "            image_decode_2 = image_decode + image_decode_2\n",
    "            image_decode_2 = tf.nn.leaky_relu(image_decode_2)\n",
    "            \n",
    "            concat_decode = tf.concat([image_decode_2, text_decode], axis=3)\n",
    "            concat_decode = self._conv_bn_leaky(concat_decode, self.df_dim * 8, [1, 1], [1, 1])\n",
    "\n",
    "            concat_decode = tf.layers.conv2d(concat_decode, 1, kernel_size=[self.s16, self.s16], strides=[self.s16, self.s16],\n",
    "                                            padding='SAME', use_bias=False, kernel_initializer=self.conv2d_initializer)\n",
    "\n",
    "            self.logits = concat_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN:\n",
    "\n",
    "    def __init__(self,\n",
    "                 hparas,\n",
    "                 training_phase,\n",
    "                 stage,\n",
    "                 dataset_path,\n",
    "                 ckpt_path,\n",
    "                 inference_path,\n",
    "                 recover=None):\n",
    "        self.hparas = hparas\n",
    "        self.train = training_phase\n",
    "        self.stage = stage\n",
    "        self.dataset_path = dataset_path  # dataPath+'/text2ImgData.pkl'\n",
    "        self.ckpt_path = ckpt_path\n",
    "        self.sample_path = './samples'\n",
    "        self.inference_path = './inference'\n",
    "\n",
    "        self._get_session()  # get session\n",
    "        self._get_train_data_iter()  # initialize and get data iterator\n",
    "        self._input_layer()  # define input placeholder\n",
    "        self._get_inference()  # build generator and discriminator\n",
    "        self._get_loss()  # define gan loss\n",
    "        self._get_var_with_name()  # get variables for each part of model\n",
    "        self._optimize()  # define optimizer\n",
    "        self._init_vars()\n",
    "        self._get_saver()\n",
    "        self.recover = recover\n",
    "\n",
    "        if recover is not None:\n",
    "            self._load_checkpoint(recover)\n",
    "\n",
    "    def _get_train_data_iter(self):\n",
    "        if self.train:  # training data iteratot\n",
    "            if self.stage == 1:\n",
    "                iterator_train, types, shapes = data_iterator('dataset/train_caption.pkl', \n",
    "                    self.hparas['BATCH_SIZE'], training_data_generator)\n",
    "            else:\n",
    "                iterator_train, types, shapes = data_iterator('dataset/train_caption.pkl', \n",
    "                    self.hparas['BATCH_SIZE'], training_data_generator_hr)\n",
    "            iter_initializer = iterator_train.initializer\n",
    "            self.next_element = iterator_train.get_next()\n",
    "            self.sess.run(iterator_train.initializer)\n",
    "            self.iterator_train = iterator_train\n",
    "        else:  # testing data iterator\n",
    "            iterator_train, types, shapes = data_iterator_test(\n",
    "                self.dataset_path + '/test_caption.pkl', self.hparas['BATCH_SIZE'])\n",
    "            iter_initializer = iterator_train.initializer\n",
    "            self.next_element = iterator_train.get_next()\n",
    "            self.sess.run(iterator_train.initializer)\n",
    "            self.iterator_test = iterator_train\n",
    "\n",
    "    def _input_layer(self):\n",
    "        if self.train:\n",
    "            self.real_image = tf.placeholder(dtype=tf.float32, shape=[\n",
    "                  None, self.hparas['IMAGE_SIZE'][0],\n",
    "                  self.hparas['IMAGE_SIZE'][1], self.hparas['IMAGE_SIZE'][2]\n",
    "                ], name='real_image')\n",
    "        self.caption = tf.placeholder(dtype=tf.float32, shape=[None, self.hparas['EMBED_DIM']], name='caption')\n",
    "        self.z_noise = tf.placeholder(tf.float32, [None, self.hparas['Z_DIM']], name='z_noise')\n",
    "\n",
    "    def _get_inference(self):\n",
    "        if self.train:\n",
    "            if self.stage == 1:\n",
    "                # GAN training\n",
    "                # generating image\n",
    "                self.generator = Generator(self.z_noise, self.caption, training_phase=True,\n",
    "                                           hparas=self.hparas, reuse=False)\n",
    "\n",
    "                # discriminize\n",
    "                # fake image with matched text\n",
    "                self.fake_discriminator = Discriminator(self.generator.outputs, self.caption, training_phase=True,\n",
    "                                                        hparas=self.hparas, reuse=False)\n",
    "\n",
    "                # real image with real text\n",
    "                self.real_discriminator = Discriminator(self.real_image, self.caption, training_phase=True,\n",
    "                                                        hparas=self.hparas, reuse=True)\n",
    "\n",
    "                # real image with mismatched text\n",
    "                self.wrong_discriminator = Discriminator(tf.random_shuffle(self.real_image), self.caption, \n",
    "                                                         training_phase=True, hparas=self.hparas, reuse=True)\n",
    "                \n",
    "            #stage 2\n",
    "            else:\n",
    "                self.generator = Generator(self.z_noise, self.caption, training_phase=False,\n",
    "                                           hparas=self.hparas, reuse=False)\n",
    "                \n",
    "                self.generator_2 = Generator_2(self.generator.outputs, self.caption, training_phase=True,\n",
    "                                               hparas=self.hparas, reuse=False)\n",
    "\n",
    "                self.fake_discriminator = Discriminator_2(self.generator_2.outputs, self.caption, training_phase=True,\n",
    "                                                          hparas=self.hparas, reuse=False)\n",
    "\n",
    "                self.real_discriminator = Discriminator_2(self.real_image, self.caption, training_phase=True,\n",
    "                                                          hparas=self.hparas, reuse=True)\n",
    "\n",
    "                self.wrong_discriminator = Discriminator_2(tf.random_shuffle(self.real_image), self.caption,\n",
    "                                                           training_phase=True, hparas=self.hparas, reuse=True)\n",
    "                \n",
    "        else:  # inference mode\n",
    "            self.generate_image_net = Generator(\n",
    "                self.z_noise,\n",
    "                self.caption,\n",
    "                training_phase=False,\n",
    "                hparas=self.hparas,\n",
    "                reuse=False)\n",
    "            if self.stage == 2:\n",
    "                self.generate_image_net_2 = Generator_2(\n",
    "                    self.generate_image_net.outputs,\n",
    "                    self.caption,\n",
    "                    training_phase=False,\n",
    "                    hparas=self.hparas,\n",
    "                    reuse=False)\n",
    "                \n",
    "\n",
    "    def _get_loss(self):\n",
    "        if self.train:\n",
    "            d_loss1 = tf.reduce_mean(\n",
    "                tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                    logits=self.real_discriminator.logits,\n",
    "                    labels=tf.ones_like(self.real_discriminator.logits),\n",
    "                    name='d_loss1'))\n",
    "            d_loss2 = tf.reduce_mean(\n",
    "                tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                    logits=self.fake_discriminator.logits,\n",
    "                    labels=tf.zeros_like(self.fake_discriminator.logits),\n",
    "                    name='d_loss2'))\n",
    "            d_loss3 = tf.reduce_mean(\n",
    "                tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                    logits=self.wrong_discriminator.logits,\n",
    "                    labels=tf.zeros_like(self.wrong_discriminator.logits),\n",
    "                    name='d_loss3'))\n",
    "            self.d_loss = d_loss1 + (d_loss2 + d_loss3) / 2\n",
    "            if self.stage == 1:\n",
    "                self.g_loss = tf.reduce_mean(\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                        logits=self.fake_discriminator.logits,\n",
    "                        labels=tf.ones_like(self.fake_discriminator.logits),\n",
    "                        name='g_loss')) + 2 * self.generator.KLloss\n",
    "            else:\n",
    "                self.g_loss = tf.reduce_mean(\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                        logits=self.fake_discriminator.logits,\n",
    "                        labels=tf.ones_like(self.fake_discriminator.logits),\n",
    "                        name='g_loss')) + 2 * self.generator_2.KLloss\n",
    "\n",
    "    def _optimize(self):\n",
    "        if self.train:\n",
    "            with tf.variable_scope('learning_rate'):\n",
    "                self.lr_var = tf.Variable(self.hparas['LR'], trainable=False)\n",
    "            \n",
    "            discriminator_optimizer = tf.train.AdamOptimizer(self.lr_var, beta1=self.hparas['BETA'])\n",
    "            generator_optimizer = tf.train.AdamOptimizer(self.lr_var, beta1=self.hparas['BETA'])\n",
    "            if self.stage == 1:\n",
    "                d_update = tf.get_collection(tf.GraphKeys.UPDATE_OPS,'discriminator_1')\n",
    "                with tf.control_dependencies(d_update):\n",
    "                    self.d_optim = discriminator_optimizer.minimize(self.d_loss, var_list=self.discrim_vars)\n",
    "                g_update = tf.get_collection(tf.GraphKeys.UPDATE_OPS,'generator_1')\n",
    "                with tf.control_dependencies(g_update):\n",
    "                    self.g_optim = generator_optimizer.minimize(self.g_loss, var_list=self.generator_vars)           \n",
    "            else:\n",
    "                d_update = tf.get_collection(tf.GraphKeys.UPDATE_OPS,'discriminator_2')\n",
    "                with tf.control_dependencies(d_update):\n",
    "                    self.d_optim = discriminator_optimizer.minimize(self.d_loss, var_list=self.discrim_vars_2)\n",
    "                g_update = tf.get_collection(tf.GraphKeys.UPDATE_OPS,'generator_2')\n",
    "                with tf.control_dependencies(g_update):\n",
    "                    self.g_optim = generator_optimizer.minimize(self.g_loss, var_list=self.generator_vars_2) \n",
    "\n",
    "    def training(self):\n",
    "\n",
    "        for _epoch in range(self.hparas['N_EPOCH']):\n",
    "            start_time = time.time()\n",
    "\n",
    "            if _epoch != 0 and (_epoch % self.hparas['DECAY_EVERY'] == 0):\n",
    "                new_lr_decay = self.hparas['LR_DECAY'] ** (_epoch // self.hparas['DECAY_EVERY'])\n",
    "                self.sess.run(tf.assign(self.lr_var, self.hparas['LR'] * new_lr_decay))\n",
    "                print(\"new lr %f\" % (self.hparas['LR'] * new_lr_decay))\n",
    "\n",
    "            n_batch_epoch = int(self.hparas['N_SAMPLE'] / self.hparas['BATCH_SIZE'])\n",
    "            \n",
    "            for _step in range(n_batch_epoch):\n",
    "                step_time = time.time()\n",
    "\n",
    "                image_batch, caption_batch  = self.sess.run(self.next_element)\n",
    "                \n",
    "                #caption_batch = caption_batch[:, np.random.choice(caption_batch.shape[1], 4, replace=False), :]\n",
    "                #caption_batch = np.mean(caption_batch, axis=1)\n",
    "                \n",
    "                caption_tmp = np.zeros([caption_batch.shape[0], caption_batch.shape[2]])\n",
    "                for i, batch in enumerate(caption_batch):\n",
    "                    random_idx = np.random.choice(batch.shape[0], 4, replace=False)\n",
    "                    mean_sum = 0.0\n",
    "                    count = 0\n",
    "                    for idx in random_idx:\n",
    "                        if np.sum(batch[idx][:100]) != 0:\n",
    "                            mean_sum += batch[idx]\n",
    "                            count += 1\n",
    "                            \n",
    "                    if count != 0:\n",
    "                        caption_tmp[i] = mean_sum / count\n",
    "                    else:\n",
    "                        for j in range(10):\n",
    "                            if np.sum(batch[j][:100]) != 0:\n",
    "                                caption_tmp[i] = batch[j]\n",
    "                caption_batch = caption_tmp\n",
    "                              \n",
    "                batch_size = image_batch.shape[0]\n",
    "                b_z = np.random.normal(loc=0.0, scale=1.0, size=(batch_size, self.hparas['Z_DIM'])).astype(np.float32)\n",
    "                # update discriminator\n",
    "                self.discriminator_error, _ = self.sess.run([self.d_loss, self.d_optim],\n",
    "                    feed_dict={self.real_image: image_batch, self.caption: caption_batch, self.z_noise: b_z})\n",
    "\n",
    "                # update generate\n",
    "                self.generator_error, _ = self.sess.run([self.g_loss, self.g_optim], \n",
    "                    feed_dict={self.real_image: image_batch, self.caption: caption_batch, self.z_noise: b_z})\n",
    "                if _step % 50 == 0:\n",
    "                    print(\"Epoch: [%2d/%2d] [%4d/%4d] time: %4.4fs, d_loss: %.3f, g_loss: %.3f\"\n",
    "                          % (_epoch, self.hparas['N_EPOCH'], _step, n_batch_epoch,\n",
    "                             time.time() - step_time, self.discriminator_error, self.generator_error))\n",
    "            if _epoch != 0 and (_epoch + 1) % 5 == 0:\n",
    "                _epoch_total = _epoch\n",
    "                if self.recover is not None:\n",
    "                    _epoch_total = self.recover + 1 + _epoch\n",
    "                self._save_checkpoint(_epoch_total)\n",
    "                self._sample_visiualize(_epoch_total)\n",
    "\n",
    "    def inference(self):\n",
    "        for _iters in range(30):\n",
    "            caption, idx = self.sess.run(self.next_element)\n",
    "            batch_size = caption.shape[0]\n",
    "            z_seed = np.random.normal(loc=0.0, scale=1.0, size=(batch_size, self.hparas['Z_DIM'])).astype(np.float32)\n",
    "            z_seed = np.zeros((batch_size, self.hparas['Z_DIM'])).astype(np.float32)\n",
    "            \n",
    "            if self.stage == 1:\n",
    "                img_gen = self.sess.run(self.generate_image_net.outputs, feed_dict={self.caption: caption, \n",
    "                                                                                    self.z_noise: z_seed})\n",
    "            else:\n",
    "                img_gen = self.sess.run(self.generate_image_net_2.outputs, feed_dict={self.caption: caption, \n",
    "                                                                                    self.z_noise: z_seed})\n",
    "            img_gen = (img_gen + 1) / 2\n",
    "            for i in range(batch_size):\n",
    "                scipy.misc.imsave(self.inference_path + '/inference_{:04d}.png'.format(idx[i]), img_gen[i])\n",
    "\n",
    "    def _init_vars(self):\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    def _get_session(self):\n",
    "        self.sess = tf.Session()\n",
    "\n",
    "    def _get_saver(self):\n",
    "        self.g_saver = tf.train.Saver(var_list=self.generator_vars, max_to_keep=40)\n",
    "        if self.stage == 1:\n",
    "            if self.train:\n",
    "                self.d_saver = tf.train.Saver(var_list=self.discrim_vars, max_to_keep=40)\n",
    "        else:\n",
    "            self.g_saver_2 = tf.train.Saver(var_list=self.generator_vars_2, max_to_keep=40)\n",
    "            if self.train:\n",
    "                self.d_saver_2 = tf.train.Saver(var_list=self.discrim_vars_2, max_to_keep=40)\n",
    "            self.g_saver_2 = tf.train.Saver(var_list=self.generator_vars_2, max_to_keep=40)\n",
    "\n",
    "    def _sample_visiualize(self, epoch):\n",
    "        ni = int(np.ceil(np.sqrt(self.hparas['BATCH_SIZE'])))\n",
    "        sample_size = self.hparas['BATCH_SIZE']\n",
    "        sample_sentence = []\n",
    "        for i in range(len(sample_rnn)):\n",
    "            for _ in range(sample_size // ni):\n",
    "                sample_sentence.append(np.hstack((sample_rnn[i], sample_caption[i][2400:])))\n",
    "\n",
    "        sample_seed = np.random.normal(loc=0.0, scale=1.0, size=(sample_size, self.hparas['Z_DIM'])).astype(np.float32)\n",
    "        \n",
    "        if self.stage == 1:\n",
    "            img_gen = self.sess.run(self.generator.outputs, feed_dict={self.caption: sample_sentence, \n",
    "                                                                       self.z_noise: sample_seed})\n",
    "        else:\n",
    "            img_gen = self.sess.run(self.generator_2.outputs, feed_dict={self.caption: sample_sentence, \n",
    "                                                                       self.z_noise: sample_seed})\n",
    "        img_gen = (img_gen + 1) / 2\n",
    "        img_gen = skimage.transform.resize(img_gen, (64, 64, 3), mode='constant')\n",
    "        save_images(img_gen, [ni, ni], self.sample_path + '/train_{:02d}.png'.format(epoch))\n",
    "\n",
    "    def _get_var_with_name(self):\n",
    "        t_vars = tf.trainable_variables()\n",
    "        generator_global = tf.global_variables('generator_1')\n",
    "        generator_moving = [g for g in generator_global if 'moving_mean' in g.name or 'moving_variance' in g.name]\n",
    "        \n",
    "        discrim_global = tf.global_variables('discriminator_1')\n",
    "        discrim_moving = [g for g in discrim_global if 'moving_mean' in g.name or 'moving_variance' in g.name]\n",
    "        \n",
    "        self.generator_vars = [var for var in t_vars if 'generator_1' in var.name] + generator_moving\n",
    "        self.discrim_vars = [var for var in t_vars if 'discriminator_1' in var.name] + discrim_moving\n",
    "        \n",
    "        generator_global_2 = tf.global_variables('generator_2')\n",
    "        generator_moving_2 = [g for g in generator_global_2 if 'moving_mean' in g.name or 'moving_variance' in g.name]\n",
    "        \n",
    "        discrim_global_2 = tf.global_variables('discriminator_2')\n",
    "        discrim_moving_2 = [g for g in discrim_global_2 if 'moving_mean' in g.name or 'moving_variance' in g.name] \n",
    "            \n",
    "        self.generator_vars_2 = [var for var in t_vars if 'generator_2' in var.name] + generator_moving_2\n",
    "        self.discrim_vars_2 = [var for var in t_vars if 'discriminator_2' in var.name] + discrim_moving_2\n",
    " \n",
    "            \n",
    "    def _load_checkpoint(self, recover):\n",
    "        self.g_saver.restore(self.sess,self.ckpt_path + 'g_model_' + str(recover) + '.ckpt')\n",
    "        if self.stage == 1:\n",
    "            generator_varsif self.train:\n",
    "                self.d_saver.restore(self.sess,self.ckpt_path + 'd_model_' + str(recover) + '.ckpt')  \n",
    "        elif tf.train.checkpoint_exists(self.ckpt_path + 'g_model_2_' + str(recover) + '.ckpt'):\n",
    "            self.g_saver_2.restore(self.sess,self.ckpt_path + 'g_model_2_' + str(recover) + '.ckpt')\n",
    "            if self.train:\n",
    "                self.d_saver_2.restore(self.sess,self.ckpt_path + 'd_model_2_' + str(recover) + '.ckpt')\n",
    "                \n",
    "        print('-----success restored checkpoint--------')\n",
    "\n",
    "    def _save_checkpoint(self, epoch):\n",
    "        self.g_saver.save(self.sess,self.ckpt_path + 'g_model_' + str(epoch) + '.ckpt')   \n",
    "        if self.stage == 1:\n",
    "            self.d_saver.save(self.sess,self.ckpt_path + 'd_model_' + str(epoch) + '.ckpt')\n",
    "        else:\n",
    "            self.g_saver_2.save(self.sess,self.ckpt_path + 'g_model_2_' + str(epoch) + '.ckpt')\n",
    "            self.d_saver_2.save(self.sess,self.ckpt_path + 'd_model_2_' + str(epoch) + '.ckpt')\n",
    "        print('-----success saved checkpoint--------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage I Parameters\n",
    "def get_hparas():\n",
    "    hparas = {\n",
    "        'EMBED_DIM': 2600,  # word embedding dimension\n",
    "        'TEXT_DIM': 128,  # text embedding dimension\n",
    "        'Z_DIM': 100,  # random noise z dimension\n",
    "        'IMAGE_SIZE': [64, 64, 3],  # render image size\n",
    "        'LR_SIZE': 64,\n",
    "        'BATCH_SIZE': 64,\n",
    "        'LR': 0.0002,\n",
    "        'DECAY_EVERY': 50,\n",
    "        'LR_DECAY': 0.5,\n",
    "        'BETA': 0.5,  # AdamOptimizer parameter\n",
    "        'N_EPOCH': 600,\n",
    "        'N_SAMPLE': 7370\n",
    "    }\n",
    "    return hparas\n",
    "\n",
    "checkpoint_path = './checkpoint/'\n",
    "inference_path = './inference'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage I Training\n",
    "tf.reset_default_graph()\n",
    "\n",
    "gan = GAN(\n",
    "    get_hparas(),\n",
    "    training_phase=True,\n",
    "    stage=1,\n",
    "    dataset_path=data_path,\n",
    "    ckpt_path=checkpoint_path,\n",
    "    inference_path=inference_path,\n",
    "    recover=None)\n",
    "gan.training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage II Parameters\n",
    "def get_hparas_2():\n",
    "    hparas = {\n",
    "        'EMBED_DIM': 2600,  # word embedding dimension\n",
    "        'TEXT_DIM': 128,  # text embedding dimension\n",
    "        'Z_DIM': 100,  # random noise z dimension\n",
    "        'IMAGE_SIZE': [256, 256, 3],  # render image size\n",
    "        'LR_SIZE': 64,\n",
    "        'BATCH_SIZE': 64,\n",
    "        'LR': 0.0002,\n",
    "        'DECAY_EVERY': 100,\n",
    "        'LR_DECAY': 0.5,\n",
    "        'BETA': 0.5,  # AdamOptimizer parameter\n",
    "        'N_EPOCH': 600,\n",
    "        'N_SAMPLE': 7370\n",
    "    }\n",
    "    return hparas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage II Training\n",
    "tf.reset_default_graph()\n",
    "\n",
    "gan = GAN(\n",
    "    get_hparas_2(),\n",
    "    training_phase=True,\n",
    "    stage=2,\n",
    "    dataset_path=data_path,\n",
    "    ckpt_path=checkpoint_path,\n",
    "    inference_path=inference_path,\n",
    "    recover=594)\n",
    "gan.training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iterator_test(filenames, batch_size):\n",
    "    data = pd.read_pickle(filenames)\n",
    "    captions = data['Captions'].values\n",
    "    caption = []\n",
    "    for i in range(len(captions)):\n",
    "        caption.append(np.hstack((np.array(captions[i])[1:], \n",
    "                                  test_caption[np.array(captions[i])[0].astype(np.int32)][2400:])))\n",
    "        #caption.append(test_caption[captions[i]])\n",
    "    caption = np.asarray(caption)\n",
    "    index = data['ID'].values\n",
    "    index = np.asarray(index)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((caption, index))\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    output_types = dataset.output_types\n",
    "    output_shapes = dataset.output_shapes\n",
    "\n",
    "    return iterator, output_types, output_shapes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
